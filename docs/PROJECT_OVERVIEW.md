# Dias-Toffoli: Project Overview

> A modular, web-based hand gesture controller for real-time audio-visual generation.

## ğŸ¯ Vision

**Dias-Toffoli** is a creative coding platform that transforms hand movements captured via webcam into expressive audio-visual experiences. The system runs entirely in the browser, making it accessible, portable, and easy to deploy via Docker containers.

## ğŸŒŸ Core Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Camera    â”‚â”€â”€â”€â–¶â”‚   Hand Tracker   â”‚â”€â”€â”€â–¶â”‚  Controllers     â”‚â”€â”€â”€â–¶â”‚   Generators    â”‚
â”‚   (Image)   â”‚    â”‚   (MediaPipe)    â”‚    â”‚  (State Machine) â”‚    â”‚ (Audio/Visual)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                       â”‚                       â”‚
       â–¼                    â–¼                       â–¼                       â–¼
  [ImageFrame]        [HandPoints]           [ControlState]          [Output]
```

The system is designed with **strict separation of concerns**:

1. **HandTracker**: Captures video frames and extracts hand landmark data
2. **Controllers**: Transform hand data into control states (gestures, positions, etc.)
3. **Generators**: Consume control states to produce audio or visual output

Each module communicates through **well-defined typed interfaces**, enabling:
- Easy replacement of any component
- Independent testing and development
- Creative experimentation with new controllers/generators

## ğŸ¨ Use Cases

### Music Generation
- Move hand left/right â†’ control pitch
- Move hand up/down â†’ control volume
- Close/open hand â†’ control timbre
- Multiple hands â†’ polyphonic synthesis

### Visual Art Generation
- Hand position â†’ particle attractor
- Hand velocity â†’ color hue
- Gesture recognition â†’ trigger visual effects

### Interactive Installations
- Combine multiple controllers and generators
- Create custom gesture vocabularies
- Design immersive audio-visual experiences

## ğŸ¯ Design Goals

1. **Modularity**: Replace any component without breaking others
2. **Type Safety**: All interfaces have strict TypeScript types
3. **Real-time Streaming**: All data flows as observable streams
4. **Web-First**: Runs in any modern browser
5. **Containerized**: One command to deploy anywhere
6. **AI-Friendly**: Code is organized for easy AI-assisted development

## ğŸ“Š Key Metrics

- **Latency Target**: < 50ms from camera to output
- **Frame Rate**: 30+ FPS hand tracking
- **Audio Latency**: < 20ms using Web Audio API
- **Browser Support**: Chrome, Firefox, Edge (modern versions)

## ğŸ”— Related Documents

- [ARCHITECTURE.md](./ARCHITECTURE.md) - System architecture and module design
- [TECH_STACK.md](./TECH_STACK.md) - Technology choices and rationale
- [DATA_FLOW.md](./DATA_FLOW.md) - Data types and streaming interfaces
- [MODULES/](./MODULES/) - Detailed module specifications
- [COPILOT_INSTRUCTIONS.md](./COPILOT_INSTRUCTIONS.md) - AI coding assistant guidelines
- [DEPLOYMENT.md](./DEPLOYMENT.md) - Docker and deployment instructions
